{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e309d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.real_datasets import act_preprocesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da81ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = act_preprocesser(\"../attic/data/ATC/atc_20121024_20121205.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54a53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_size = X.shape[0]\n",
    "seed = 42\n",
    "test_percentage = 0.1\n",
    "random_number_generator = np.random.default_rng(seed=seed)\n",
    "train_size, test_size = dataset_size - int(dataset_size * test_percentage), int(dataset_size * test_percentage)\n",
    "\n",
    "all_indexes = np.arange(0, dataset_size, 1)\n",
    "train_indexes = np.random.choice(all_indexes, train_size, replace=False)\n",
    "test_mask = np.ones_like(all_indexes).astype(bool)\n",
    "test_indexes = all_indexes[test_mask]\n",
    "\n",
    "X_train, y_train = X[train_indexes, :], y[train_indexes, :]\n",
    "X_test, y_test = X[test_indexes, :], y[test_indexes, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ed9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_scaler = StandardScaler().fit(X_train)\n",
    "targets_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train_scaled, y_train_scaled = features_scaler.transform(X_train), targets_scaler.transform(y_train)\n",
    "X_test_scaled, y_test_scaled = features_scaler.transform(X_test), targets_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6090f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "X_train_tensor, y_train_tensor = torch.from_numpy(X_train_scaled).to(torch.float32), torch.from_numpy(y_train_scaled).to(torch.float32)\n",
    "X_test_tensor, y_test_tensor = torch.from_numpy(X_test_scaled), torch.from_numpy(y_test_scaled)\n",
    "\n",
    "train_tensor_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_tensor_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0684bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pushforward_operators import RectifiedFlowQuantile\n",
    "from classes import TrainParameters\n",
    "\n",
    "quantile = RectifiedFlowQuantile(\n",
    "    feature_dimension=160,\n",
    "    response_dimension=32,\n",
    "    hidden_dimension=32,\n",
    "    number_of_hidden_layers=8,\n",
    ")\n",
    "\n",
    "train_parameters = TrainParameters(\n",
    "    number_of_epochs_to_train=200,\n",
    "    optimizer_parameters=dict(\n",
    "        lr=1e-2,\n",
    "    ),\n",
    "    scheduler_parameters=dict(\n",
    "        eta_min=0\n",
    "    ),\n",
    "    warmup_iterations=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00addc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Flow Loss: 20.9090, LR: 0.000000: 100%|██████████| 200/200 [07:56<00:00,  2.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RectifiedFlowQuantile(\n",
       "  (time_embedding_network): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (vector_field_network): FFNN(\n",
       "    (activation_function): Softplus(beta=1.0, threshold=20.0)\n",
       "    (potential_network): Sequential(\n",
       "      (0): Linear(in_features=352, out_features=32, bias=True)\n",
       "      (1): Softplus(beta=1.0, threshold=20.0)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (3): Softplus(beta=1.0, threshold=20.0)\n",
       "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (5): Softplus(beta=1.0, threshold=20.0)\n",
       "      (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (7): Softplus(beta=1.0, threshold=20.0)\n",
       "      (8): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (9): Softplus(beta=1.0, threshold=20.0)\n",
       "      (10): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (11): Softplus(beta=1.0, threshold=20.0)\n",
       "      (12): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (13): Softplus(beta=1.0, threshold=20.0)\n",
       "      (14): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (15): Softplus(beta=1.0, threshold=20.0)\n",
       "      (16): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (17): Softplus(beta=1.0, threshold=20.0)\n",
       "      (18): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (Y_scaler): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile.fit(\n",
    "    dataloader=train_dataloader,\n",
    "    train_parameters=train_parameters,\n",
    "    number_of_rectifying_operations=1,\n",
    "    jacobian_symmetry_penalty_weight=0.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd4be2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RectifiedFlowQuantile' object has no attribute '_predict_vector_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m u_samples = torch.zeros(\u001b[32m1\u001b[39m, target_space_size)\n\u001b[32m     19\u001b[39m x_sample_repeated = x_sample.repeat(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).to(dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m y_scaled = \u001b[43mquantile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush_u_given_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sample_repeated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_evaluations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m y_prediction = targets_scaler.inverse_transform(y_scaled.detach().numpy())\n\u001b[32m     23\u001b[39m x_sample_unscaled = features_scaler.inverse_transform(x_sample.detach().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conformal_prediction_in_large_dimensions/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conformal_prediction_in_large_dimensions/src/pushforward_operators/rectified_flow/rectified_flow.py:280\u001b[39m, in \u001b[36mRectifiedFlowQuantile.push_u_given_x\u001b[39m\u001b[34m(self, u, x, number_of_evaluations)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m evaluation_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_evaluations):\n\u001b[32m    279\u001b[39m     interpolation_times = (evaluation_index + \u001b[32m0.5\u001b[39m) * dt\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     vector_field_prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_vector_field\u001b[49m(\n\u001b[32m    281\u001b[39m         state=state,\n\u001b[32m    282\u001b[39m         condition=x_tensor,\n\u001b[32m    283\u001b[39m         interpolation_times=interpolation_times,\n\u001b[32m    284\u001b[39m     )\n\u001b[32m    285\u001b[39m     state = state + dt * vector_field_prediction\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unscale_y(state).detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conformal_prediction_in_large_dimensions/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'RectifiedFlowQuantile' object has no attribute '_predict_vector_field'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "feature_position_x_slice = slice(64, 96)\n",
    "feature_position_y_slice = slice(96, 128)\n",
    "\n",
    "target_position_x_slice = slice(0, 16)\n",
    "target_position_y_slice = slice(16, 32)\n",
    "\n",
    "for test_idx in range(20):\n",
    "\n",
    "    number_of_samples = 8\n",
    "    x_sample, y_sample = X_test_tensor[test_idx: test_idx+1, :], y_test_tensor[test_idx: test_idx+1, :]\n",
    "    target_space_size = y_sample.shape[-1]\n",
    "    u_samples = torch.zeros(1, target_space_size)\n",
    "    x_sample_repeated = x_sample.repeat(1, 1).to(dtype=torch.float32)\n",
    "    y_scaled = quantile.push_u_given_x(u_samples, x_sample_repeated, number_of_evaluations=1000)\n",
    "    y_prediction = targets_scaler.inverse_transform(y_scaled.detach().numpy())\n",
    "    \n",
    "    x_sample_unscaled = features_scaler.inverse_transform(x_sample.detach().numpy())\n",
    "    y_sample_unscaled = targets_scaler.inverse_transform(y_sample.detach().numpy())\n",
    "\n",
    "    map_folderpath = \"../attic/data/ATC\"\n",
    "    yaml_path = f\"{map_folderpath}/ATC-map/localization_grid.yaml\"\n",
    "\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "\n",
    "    img_path = meta[\"image\"]\n",
    "    res = float(meta[\"resolution\"])\n",
    "    origin_x, origin_y, origin_yaw = meta[\"origin\"]\n",
    "\n",
    "    img = mpimg.imread(f\"{map_folderpath}/ATC-map/{img_path}\")\n",
    "\n",
    "    img = np.array(img)\n",
    "    if img.ndim == 3:\n",
    "        img = img[..., 0]\n",
    "\n",
    "    h, w = img.shape\n",
    "\n",
    "    x0 = origin_x\n",
    "    y0 = origin_y\n",
    "    x1 = origin_x + w * res\n",
    "    y1 = origin_y + h * res\n",
    "\n",
    "    sample_idx = torch.randint(0, y_prediction.shape[0], (1, ))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    ax.imshow(img, cmap=\"gray\", extent=[x0, x1, y0, y1])\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlabel(\"x [m]\")\n",
    "    ax.set_ylabel(\"y [m]\")\n",
    "    ax.set_title(\"Scale-accurate building grid\")\n",
    "\n",
    "\n",
    "    ax.scatter(\n",
    "        x_sample_unscaled[0, feature_position_x_slice] / 1000,\n",
    "        x_sample_unscaled[0, feature_position_y_slice] / 1000,\n",
    "        c=\"blue\",\n",
    "        label=\"Context\"\n",
    "    )\n",
    "    ax.scatter(\n",
    "        y_sample_unscaled[0, target_position_x_slice] / 1000,\n",
    "        y_sample_unscaled[0, target_position_y_slice] / 1000,\n",
    "        c=\"red\",\n",
    "        label=\"Ground Truth\",\n",
    "        marker='x'\n",
    "    )\n",
    "\n",
    "    for sample_idx in range(0, min(8, y_prediction.shape[0])):\n",
    "        ax.scatter(\n",
    "            y_prediction[sample_idx, target_position_x_slice] / 1000,\n",
    "            y_prediction[sample_idx, target_position_y_slice] / 1000,\n",
    "            s=4,\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    plt.title(f\"Index: {test_idx}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
